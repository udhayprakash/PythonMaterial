WEBVTT

1
00:00:00.774 --> 00:00:03.252
Hey there! So today we are going to cover

2
00:00:03.252 --> 00:00:06.644
how to start a Scrapy project; so let's begin right away.

3
00:00:06.644 --> 00:00:10.115
The first thing that you need to do is to open Terminal so,

4
00:00:10.115 --> 00:00:14.282
in my case, I right-click and then select "Open Terminal".

5
00:00:15.093 --> 00:00:18.648
Then, if we maximize the output and type in

6
00:00:18.648 --> 00:00:22.064
scrapy, we will see a bunch of commands.

7
00:00:22.064 --> 00:00:25.043
The first one is the Scrapy version.

8
00:00:25.043 --> 00:00:29.046
The second thing is if there are any active projects,

9
00:00:29.046 --> 00:00:30.870
this message would be different,

10
00:00:30.870 --> 00:00:33.814
of course, if we were in our root directory,

11
00:00:33.814 --> 00:00:36.897
or aka, if we created a Scrapy project.

12
00:00:38.131 --> 00:00:40.869
The very next message is the usage.

13
00:00:40.869 --> 00:00:44.864
Here we always have to run the "scrapy" command first

14
00:00:44.864 --> 00:00:48.595
and then print out the command that we want to use,

15
00:00:48.595 --> 00:00:50.779
options, and finally, arguments.

16
00:00:50.779 --> 00:00:54.089
As you will see throughout this course using,

17
00:00:54.089 --> 00:00:57.506
really, Scrapy is fairly simple and easy.

18
00:00:58.890 --> 00:01:01.432
And, let's see, so the very next thing

19
00:01:01.432 --> 00:01:03.801
is available commands.

20
00:01:03.801 --> 00:01:05.949
So here we have a bunch of commands.

21
00:01:05.949 --> 00:01:07.926
The first one is "bench".

22
00:01:07.926 --> 00:01:10.311
I rarely use this command to be honest,

23
00:01:10.311 --> 00:01:14.478
and it's mainly used for benching out, or really

24
00:01:14.480 --> 00:01:18.647
figuring out the exact performance of your spider code.

25
00:01:19.179 --> 00:01:22.388
The very second thing is the command "fetch".

26
00:01:22.388 --> 00:01:25.475
This will pretty much fetch a URL, as you can see,

27
00:01:25.475 --> 00:01:28.496
using the Scrapy downloader or, in other words,

28
00:01:28.496 --> 00:01:32.019
it will just open the URL with Scrapy.

29
00:01:32.019 --> 00:01:34.005
The third thing is "genspider".

30
00:01:34.005 --> 00:01:37.259
This will be used so it's going to generate

31
00:01:37.259 --> 00:01:40.157
a new spider, really, with the template.

32
00:01:40.157 --> 00:01:43.124
So Scrapy has a bunch of templates.

33
00:01:43.124 --> 00:01:46.207
We will mostly use their default one,

34
00:01:47.076 --> 00:01:49.481
but they offer, also, crawl template

35
00:01:49.481 --> 00:01:53.417
for crawling entire site and then printing out

36
00:01:53.417 --> 00:01:56.342
all of the different rules that you would like to get,

37
00:01:56.342 --> 00:01:59.796
or the pages that you would like to crawl.

38
00:01:59.796 --> 00:02:03.031
The fourth option is "runspider".

39
00:02:03.031 --> 00:02:06.568
This will be covered in the separate video

40
00:02:06.568 --> 00:02:09.615
that I will record and it's mainly used

41
00:02:09.615 --> 00:02:11.839
when you have some simple, maybe,

42
00:02:11.839 --> 00:02:13.844
Scrapy projects or when you would

43
00:02:13.844 --> 00:02:17.011
like to simplify the Scrapy structure.

44
00:02:18.700 --> 00:02:20.598
The "settings", this will just print out

45
00:02:20.598 --> 00:02:22.270
different Scrapy settings.

46
00:02:22.270 --> 00:02:26.437
"shell" is one of the most well-known Scrapy features

47
00:02:28.087 --> 00:02:31.407
and it will be heavily used whenever

48
00:02:31.407 --> 00:02:35.574
we develop any kind of Scrapy project to test out,

49
00:02:35.736 --> 00:02:39.111
or, really, to see if data points are there

50
00:02:39.111 --> 00:02:42.840
and to test out our code, in general, in small pieces

51
00:02:42.840 --> 00:02:45.833
and then copy and paste the output or, really,

52
00:02:45.833 --> 00:02:49.607
the commands that we write in our shell to the Scrapy code.

53
00:02:49.607 --> 00:02:53.153
"startproject", this will be covered in a minute or so

54
00:02:53.153 --> 00:02:55.226
and it will be our first command

55
00:02:55.226 --> 00:02:58.202
that we will input in Scrapy and it will,

56
00:02:58.202 --> 00:03:00.372
obviously, this command stands

57
00:03:00.372 --> 00:03:04.395
for starting, or creating, a new project.

58
00:03:04.395 --> 00:03:06.571
Then Scrapy "version", so if we type in,

59
00:03:06.571 --> 00:03:09.202
for example, Scrapy version we will see

60
00:03:09.202 --> 00:03:11.702
that we will get this message.

61
00:03:13.212 --> 00:03:17.212
So it's 1.1.2 and then the last command is "view".

62
00:03:18.728 --> 00:03:22.649
So this will open the URL in the browser as seen by Scrapy.

63
00:03:22.649 --> 00:03:25.232
This will also be heavily used.

64
00:03:26.328 --> 00:03:29.255
The reason why you would like to use "view"

65
00:03:29.255 --> 00:03:32.454
is to figure out what, actually, Scrapy sees.

66
00:03:32.454 --> 00:03:36.270
So opening URLs with Scrapy and with your,

67
00:03:36.270 --> 00:03:39.437
for example, Chrome, will be different,

68
00:03:40.400 --> 00:03:43.817
sometimes, especially in JavaScript-heavy pages,

69
00:03:43.817 --> 00:03:45.201
just remember that.

70
00:03:45.201 --> 00:03:49.276
So if you go to the Scrapy shell and test out,

71
00:03:49.276 --> 00:03:51.274
I don't know, this quote that you like,

72
00:03:51.274 --> 00:03:55.060
for example, to scrape and if data is not there,

73
00:03:55.060 --> 00:03:57.973
even if you wrote a couple of different selectors,

74
00:03:57.973 --> 00:04:01.083
then just make sure to use Scrapy "view" command

75
00:04:01.083 --> 00:04:04.374
to figure out if the data is actually there.

76
00:04:04.374 --> 00:04:08.541
Because on JavaScript-heavy pages, the data will not

77
00:04:09.422 --> 00:04:13.589
be sometimes generated or seen, really, by Scrapy.

78
00:04:15.077 --> 00:04:16.443
That's about it.

79
00:04:16.444 --> 00:04:19.635
So the first thing that

80
00:04:19.635 --> 00:04:22.245
we are going to do, really, is to start our project.

81
00:04:22.245 --> 00:04:25.179
So to do that we type in, or first let's

82
00:04:25.179 --> 00:04:27.611
actually change the directory to our Desktop

83
00:04:27.611 --> 00:04:31.778
so you can see the folder that Scrapy will generate here.

84
00:04:32.331 --> 00:04:36.498
To change the directory, we type in cd and then Desktop.

85
00:04:37.526 --> 00:04:41.693
And here we have, or currently, we are in our Desktop.

86
00:04:42.726 --> 00:04:44.660
And the first command, as I was saying,

87
00:04:44.660 --> 00:04:47.389
is going to be "scrapy" then you can

88
00:04:47.389 --> 00:04:49.793
pretty much copy and paste this command.

89
00:04:49.793 --> 00:04:53.793
So "scrapy startproject" and the command or option

90
00:04:54.678 --> 00:04:58.845
that you want to use is just the name of the spider

91
00:04:59.017 --> 00:05:03.184
which will be "quotes_spider", for example.

92
00:05:03.773 --> 00:05:05.867
Hit Enter and you will see the message

93
00:05:05.867 --> 00:05:08.666
that the new project is created and that

94
00:05:08.666 --> 00:05:12.272
we can start or create our first spider

95
00:05:12.272 --> 00:05:15.713
by first changing the directory into the quotes_spider.

96
00:05:15.713 --> 00:05:19.880
So in this folder, and then finally, I'm generating spider.

97
00:05:20.126 --> 00:05:23.056
So let's navigate to the quotes_spider.

98
00:05:23.056 --> 00:05:26.471
So if we copy and paste this command, hit Enter,

99
00:05:26.471 --> 00:05:30.359
you will see that currently we are in the quotes_spider.

100
00:05:30.359 --> 00:05:33.112
So if we go to the folder and, for example,

101
00:05:33.112 --> 00:05:36.983
let's go back to our Terminal and type in right now "scrapy"

102
00:05:36.983 --> 00:05:40.983
you will see that we get project is quotes_spider

103
00:05:42.127 --> 00:05:45.635
whereas, previously, we had no active projects.

104
00:05:45.635 --> 00:05:47.818
And pretty much the way that you know

105
00:05:47.818 --> 00:05:51.736
that you are in the root directory is by looking

106
00:05:51.736 --> 00:05:54.819
where the .cfg or scrapy.cfg file is.

107
00:05:56.317 --> 00:06:00.475
And this is the configuration file that Scrapy is going to

108
00:06:01.326 --> 00:06:04.326
pretty much by default, is going to create.

109
00:06:04.390 --> 00:06:06.022
And this will be covered a bit

110
00:06:06.022 --> 00:06:08.134
later on in a bit more detail.

111
00:06:08.134 --> 00:06:11.042
The very next thing that Scrapy will generate is

112
00:06:11.042 --> 00:06:15.209
the folder which is going to be the name of the spider.

113
00:06:15.466 --> 00:06:18.525
And then here we have a bunch of different files,

114
00:06:18.525 --> 00:06:20.744
as you will see, and these also are going

115
00:06:20.744 --> 00:06:24.152
to be covered in a bit more detail later on.

116
00:06:24.152 --> 00:06:27.913
__init__.py, items.py, pipelines.py and settings.py

117
00:06:27.913 --> 00:06:31.530
These are fairly really simple and beneficial

118
00:06:31.530 --> 00:06:34.170
to whenever you want to create

119
00:06:34.170 --> 00:06:37.561
some more complex Scrapy spiders,

120
00:06:37.561 --> 00:06:39.552
especially the settings.by file,

121
00:06:39.552 --> 00:06:42.272
as you will see throughout this course.

122
00:06:42.272 --> 00:06:46.439
And the "spiders" is the last thing that we will cover here.

123
00:06:47.193 --> 00:06:49.824
And "spiders" is just a folder and here

124
00:06:49.824 --> 00:06:53.300
we don't get any kind of, really,

125
00:06:53.300 --> 00:06:57.409
files or spider files, python files, whatever.

126
00:06:57.409 --> 00:07:00.697
We get just the __init__.py so if we open it

127
00:07:00.697 --> 00:07:03.394
with our preferred text editor you will see that

128
00:07:03.394 --> 00:07:07.561
it's actually just empty or commented out two sentences

129
00:07:09.043 --> 00:07:12.128
which is pretty much nothing, right.

130
00:07:12.128 --> 00:07:16.295
To generate a spider, we will go back to our Terminal

131
00:07:16.514 --> 00:07:20.640
and type in then, scrapy and then genspider so which

132
00:07:20.640 --> 00:07:24.767
will generate a new spider using predefined templates.

133
00:07:24.767 --> 00:07:27.344
So copy and paste this command.

134
00:07:27.344 --> 00:07:30.713
And then the two options, or arguments,

135
00:07:30.713 --> 00:07:34.880
that we need to input are: first the name of the spider.

136
00:07:35.751 --> 00:07:39.560
So let's say we want to name our spider "quotes",

137
00:07:39.560 --> 00:07:42.654
and that second thing is the domain

138
00:07:42.654 --> 00:07:45.839
that we are going to scrape, or the site.

139
00:07:45.839 --> 00:07:48.401
So to do that we go to Chrome

140
00:07:48.401 --> 00:07:51.422
and then pretty much copy it and paste

141
00:07:51.422 --> 00:07:54.899
this site that we would like to scrape.

142
00:07:54.899 --> 00:07:58.899
Paste it in here and let's remove the http part,

143
00:08:00.364 --> 00:08:02.912
and then we just hit Enter, really.

144
00:08:02.912 --> 00:08:07.079
And as you can see, we get a message that spider is created.

145
00:08:07.083 --> 00:08:10.098
And if we go to the spider's folder, you will see

146
00:08:10.098 --> 00:08:14.064
that quotes.py is going to be generated.

147
00:08:14.064 --> 00:08:17.354
So if we open it with a text editor, you will see

148
00:08:17.354 --> 00:08:20.801
the code is going to be pretty much,

149
00:08:20.801 --> 00:08:23.090
this would be the default code that Scrapy

150
00:08:23.090 --> 00:08:26.411
will auto-generate for the default template

151
00:08:26.411 --> 00:08:28.237
that we, in this case, used.

152
00:08:28.237 --> 00:08:31.842
So let's, for example, just generate another one.

153
00:08:31.842 --> 00:08:34.509
So scrapy genspider and example

154
00:08:36.607 --> 00:08:39.858
and let's use example.com as the domain.

155
00:08:39.858 --> 00:08:42.593
Hit enter and if we type in, for example,

156
00:08:42.593 --> 00:08:45.751
scrapy list, so this command, as you can see,

157
00:08:45.751 --> 00:08:48.726
will list out all of the available spiders.

158
00:08:48.726 --> 00:08:51.479
You will see that we will get two rows,

159
00:08:51.479 --> 00:08:54.093
or aka, two different spiders.

160
00:08:54.093 --> 00:08:56.982
So scrapy list, hit Enter and you will see

161
00:08:56.982 --> 00:08:59.492
that we have example and quotes.

162
00:08:59.492 --> 00:09:02.607
If we go back to the folder you will see

163
00:09:02.607 --> 00:09:06.048
that in the spider's folder, we have now examples.py,

164
00:09:06.048 --> 00:09:10.112
the __init__.py file, which was initially there,

165
00:09:10.112 --> 00:09:12.120
and also quotes.py file.

166
00:09:12.120 --> 00:09:14.744
So if we go to example.py you will see

167
00:09:14.744 --> 00:09:18.911
that code is pretty much going to be, or stays the same.

168
00:09:19.304 --> 00:09:22.033
The class name will be different and also,

169
00:09:22.033 --> 00:09:25.154
the name of the spider and all of the domains and start URLs

170
00:09:25.154 --> 00:09:27.797
will be different while all of the rest logic,

171
00:09:27.797 --> 00:09:31.898
such as method/function name will stay the same.

172
00:09:31.898 --> 00:09:35.164
And that would be pretty much it for this video.

173
00:09:35.164 --> 00:09:38.115
In the very next video, we are going

174
00:09:38.115 --> 00:09:41.596
to start actually scraping something

175
00:09:41.596 --> 00:09:44.846
interesting on this file. So stay tuned.

