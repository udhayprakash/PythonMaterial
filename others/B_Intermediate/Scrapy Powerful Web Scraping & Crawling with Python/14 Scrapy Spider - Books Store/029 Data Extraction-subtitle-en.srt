1
00:00:00,636 --> 00:00:02,314
Hi! So we are continuing

2
00:00:02,314 --> 00:00:05,306
from our previous video, and here we are going to grab

3
00:00:05,306 --> 00:00:07,620
some interesting data points and yield

4
00:00:07,620 --> 00:00:10,307
them finally, from every book URL.

5
00:00:10,307 --> 00:00:11,154
So let's start.

6
00:00:11,154 --> 00:00:14,494
The first one is the title one, so let's go to the Inspect.

7
00:00:14,494 --> 00:00:18,515
Most of the time it's in the &lt;h1&gt; tag, as it is here.

8
00:00:18,515 --> 00:00:20,015
So we can grab it.

9
00:00:21,133 --> 00:00:25,300
Let's actually just first go to the book URL page.

10
00:00:27,387 --> 00:00:31,281
And then we can grab it by typing in response.xpath

11
00:00:31,281 --> 00:00:33,476
and then collect every &lt;h1&gt; tag.

12
00:00:33,476 --> 00:00:35,309
In this case, there is only one,

13
00:00:35,309 --> 00:00:36,988
so if we call in the extract(),

14
00:00:36,988 --> 00:00:40,229
we will see that it's in the HTML node.

15
00:00:40,229 --> 00:00:42,687
You can also use the CSS Selector.

16
00:00:42,687 --> 00:00:46,741
In this case, the syntax is going to be a bit different.

17
00:00:46,741 --> 00:00:48,859
So as you can see, this would be the syntax

18
00:00:48,859 --> 00:00:50,973
if you're using the CSS Selectors,

19
00:00:50,973 --> 00:00:53,261
and also just select text.

20
00:00:53,261 --> 00:00:55,213
This would be the syntax.

21
00:00:55,213 --> 00:00:57,377
Let's call in the extract_first().

22
00:00:57,377 --> 00:01:01,044
And let's copy and paste this into our code.

23
00:01:01,991 --> 00:01:04,096
So this would be the title variable,

24
00:01:04,096 --> 00:01:06,008
and the second data point

25
00:01:06,008 --> 00:01:08,710
that we want to use or to select

26
00:01:08,710 --> 00:01:10,116
is going to be the price.

27
00:01:10,116 --> 00:01:13,973
Most of time, it's in some kind of container,

28
00:01:13,973 --> 00:01:16,473
mainly in &lt;div&gt;, as it is here,

29
00:01:17,529 --> 00:01:20,731
but mainly we are looking for the class name.

30
00:01:20,731 --> 00:01:23,326
And the class name is the price_color.

31
00:01:23,326 --> 00:01:26,659
So let's collect this data point, so, response.xpath,

32
00:01:26,659 --> 00:01:28,909
and then select every class

33
00:01:31,310 --> 00:01:33,893
that has the price_color in it.

34
00:01:35,209 --> 00:01:36,755
Perfect, it works.

35
00:01:36,755 --> 00:01:40,922
We'll collect text and also select first instance.

36
00:01:43,126 --> 00:01:47,293
And here, as you can see, these are unicode representation

37
00:01:47,789 --> 00:01:49,758
of the "£" sign.

38
00:01:49,758 --> 00:01:52,720
If we type in the variable name,

39
00:01:52,720 --> 00:01:56,887
which is going to be price, and then just call in the price,

40
00:01:57,233 --> 00:01:59,382
the junk sort of characters

41
00:01:59,382 --> 00:02:01,650
or the Unicode representation of the currency

42
00:02:01,650 --> 00:02:04,641
is going to stay the same, but if we print the price,

43
00:02:04,641 --> 00:02:07,741
we will see that printing out

44
00:02:07,741 --> 00:02:10,740
is going to be the currency

45
00:02:10,740 --> 00:02:13,157
that is visible, so to speak.

46
00:02:14,723 --> 00:02:17,482
So let's type in or copy and paste this.

47
00:02:17,482 --> 00:02:21,649
The third data point we want to grab is this image URL.

48
00:02:21,960 --> 00:02:25,254
Let's go to Inspect, and most of the time, as it is here,

49
00:02:25,254 --> 00:02:29,421
it's in the form of a src and also in the &lt;img&gt;.

50
00:02:29,461 --> 00:02:33,628
So let's type in response.xpath, select every image.

51
00:02:34,458 --> 00:02:38,625
Perfect, it has only one, so we will collect the first one,

52
00:02:38,879 --> 00:02:43,046
and we will also, from every img, collect src.

53
00:02:44,229 --> 00:02:46,523
So this is going to be a bit trickier,

54
00:02:46,523 --> 00:02:50,304
because this is partial URL to the page.

55
00:02:50,304 --> 00:02:54,054
So let's actually call it the image_url here.

56
00:02:55,106 --> 00:02:57,039
And what we need to do right now,

57
00:02:57,039 --> 00:03:01,206
or what I do in most of the case, is copy and paste it.

58
00:03:01,682 --> 00:03:05,849
And then pretty much inspect the image URL as it is here.

59
00:03:05,864 --> 00:03:10,031
So this is the full HTML-sorry, the full image URL.

60
00:03:11,816 --> 00:03:15,021
And let's see what is staying the same.

61
00:03:15,021 --> 00:03:18,165
So it seems like the media is also staying the same,

62
00:03:18,165 --> 00:03:21,474
so pretty much here, we can see that we need to

63
00:03:21,474 --> 00:03:25,443
replace these characters, and replace it by this one.

64
00:03:25,443 --> 00:03:29,610
So because this partial URL is going to stay the same.

65
00:03:30,931 --> 00:03:33,273
So to do that, we type in the

66
00:03:33,273 --> 00:03:36,940
image_url is equal to the image_url.replace.

67
00:03:38,301 --> 00:03:40,792
And we are replacing,

68
00:03:40,792 --> 00:03:43,555
let's see, this strings,

69
00:03:43,555 --> 00:03:46,722
and we are going to replace it with...

70
00:03:50,479 --> 00:03:53,994
In this strings, so let's see if this is going to work.

71
00:03:53,994 --> 00:03:57,577
Once again, so we are also going to need...

72
00:04:01,214 --> 00:04:04,297
We are going to need the "/" in it.

73
00:04:06,259 --> 00:04:08,787
And so, let's see if this is actually working.

74
00:04:08,787 --> 00:04:10,950
Let's copy and paste this into our code,

75
00:04:10,950 --> 00:04:15,117
or into our Shell, and image_url, print it out.

76
00:04:16,992 --> 00:04:19,819
Copy link address, and paste it in.

77
00:04:19,819 --> 00:04:22,550
And it's working perfectly well, so great.

78
00:04:22,550 --> 00:04:26,717
The fourth data point that we want to grab is rating.

79
00:04:27,482 --> 00:04:29,342
So let's Inspect it,

80
00:04:29,342 --> 00:04:31,675
and see where the rating is.

81
00:04:32,747 --> 00:04:34,613
So, it's in the form of a class,

82
00:04:34,613 --> 00:04:38,513
and here we have the three stars, so to speak,

83
00:04:38,513 --> 00:04:42,650
so we will grab the class or partial class name,

84
00:04:42,650 --> 00:04:44,658
which is going to be star-rating.

85
00:04:44,658 --> 00:04:48,825
And then we will grab the class and then extract or replace,

86
00:04:49,209 --> 00:04:51,459
use replace as we did here.

87
00:04:54,272 --> 00:04:57,022
We will replace these characters

88
00:04:58,778 --> 00:05:01,174
with pretty much nothing, so we're going to end

89
00:05:01,174 --> 00:05:04,591
with a string of the rating, pretty much.

90
00:05:06,323 --> 00:05:08,740
Let's see how we can do this.

91
00:05:09,983 --> 00:05:13,602
So, syntax for this is going to be response.xpath,

92
00:05:13,602 --> 00:05:16,811
and then, if I remember correctly,

93
00:05:16,811 --> 00:05:20,719
it's going to be the "/",

94
00:05:21,842 --> 00:05:23,425
then "*" contains,

95
00:05:25,925 --> 00:05:30,092
and then it's going to be, in the parentheses, class.

96
00:05:32,070 --> 00:05:33,660
The class is going to be,

97
00:05:33,660 --> 00:05:35,577
let's see, star-rating.

98
00:05:38,022 --> 00:05:41,315
And then, we're going to close the parentheses.

99
00:05:41,315 --> 00:05:45,118
Finally, let's see if actually this is working.

100
00:05:45,118 --> 00:05:47,833
It doesn't, because I haven't closed this.

101
00:05:47,833 --> 00:05:52,000
Perfect, it works, so let's call extract() to better see.

102
00:05:53,349 --> 00:05:57,078
Okay, so from this HTML node, pretty much all we need

103
00:05:57,078 --> 00:05:59,538
to select is going to be this class.

104
00:05:59,538 --> 00:06:02,205
So to do that, we are just going

105
00:06:03,299 --> 00:06:06,466
to type in the "@" sign, and then class.

106
00:06:07,437 --> 00:06:09,955
And it works perfectly well,

107
00:06:09,955 --> 00:06:12,622
so let's call the extract_first().

108
00:06:13,673 --> 00:06:15,402
And then, from this string,

109
00:06:15,402 --> 00:06:17,109
we're going to replace this substring

110
00:06:17,109 --> 00:06:21,228
and we are going to be left with the, once again,

111
00:06:21,228 --> 00:06:23,745
string of the rating.

112
00:06:23,745 --> 00:06:27,328
Let's go copy and paste this into our code.

113
00:06:28,571 --> 00:06:31,178
So the rating is going to be this one,

114
00:06:31,178 --> 00:06:34,874
and then we will call the rating is going to be equal

115
00:06:34,874 --> 00:06:36,824
to the rating.replace.

116
00:06:36,824 --> 00:06:40,128
Let's see what we need to replace it once again with.

117
00:06:40,128 --> 00:06:42,461
We are going to replace this

118
00:06:44,854 --> 00:06:46,404
by pretty much nothing,

119
00:06:46,404 --> 00:06:48,911
so we're going to be left, once again,

120
00:06:48,911 --> 00:06:51,328
in this case, with the Three.

121
00:06:52,229 --> 00:06:53,721
And let's see what else we can grab.

122
00:06:53,721 --> 00:06:56,380
We can also grab the description.

123
00:06:56,380 --> 00:06:59,963
Most of the time, description is going to be a bit trickier

124
00:06:59,963 --> 00:07:01,963
because it's going to be

125
00:07:03,063 --> 00:07:05,396
sort of in the paragraph, or

126
00:07:06,270 --> 00:07:09,270
also in the bolded text, in italics,

127
00:07:11,135 --> 00:07:12,620
in some kind of &lt;div&gt;, and stuff like that.

128
00:07:12,620 --> 00:07:16,037
So, in most cases, on more complex sites,

129
00:07:18,533 --> 00:07:21,883
the description is going to take a lot of time

130
00:07:21,883 --> 00:07:23,461
to actually grab it.

131
00:07:23,461 --> 00:07:26,367
In this case, it's going to actually be pretty simple.

132
00:07:26,367 --> 00:07:29,571
So we will pretty much grab it by id.

133
00:07:29,571 --> 00:07:32,680
The id's going to be a product_description.

134
00:07:32,680 --> 00:07:34,765
And then, in the product_description,

135
00:07:34,765 --> 00:07:37,682
we are going to follow the sibling,

136
00:07:38,636 --> 00:07:41,626
and we will collect or get the &lt;p&gt;

137
00:07:41,626 --> 00:07:44,445
and then we will select this text.

138
00:07:44,445 --> 00:07:46,569
So let's actually do this.

139
00:07:46,569 --> 00:07:49,497
In our Scrapy Shell, so response.xpath,

140
00:07:49,497 --> 00:07:52,747
and then we will once again go into id,

141
00:07:54,549 --> 00:07:56,299
which is going to be

142
00:07:58,576 --> 00:07:59,912
called, let's see,

143
00:07:59,912 --> 00:08:01,662
product_description.

144
00:08:03,887 --> 00:08:06,554
And then we will following-sibling

145
00:08:07,728 --> 00:08:10,730
and we will collect the &lt;p&gt; tag

146
00:08:10,730 --> 00:08:12,351
and extract text from it.

147
00:08:12,351 --> 00:08:14,421
So let's see if this is working.

148
00:08:14,421 --> 00:08:16,648
And you actually get the HTML node,

149
00:08:16,648 --> 00:08:19,387
we need to call extract(), perfect.

150
00:08:19,387 --> 00:08:22,183
So the beginning of the description

151
00:08:22,183 --> 00:08:25,266
is going to be "It's hard to imagine"

152
00:08:26,745 --> 00:08:30,098
and the last sting or word is going to be "more."

153
00:08:30,098 --> 00:08:32,959
So it works well in this case, but like I said,

154
00:08:32,959 --> 00:08:36,088
most of the time, it's going to be a bit trickier,

155
00:08:36,088 --> 00:08:39,507
because the description is going to be

156
00:08:39,507 --> 00:08:43,674
more than one data point that you need to collect.

157
00:08:45,457 --> 00:08:49,374
Let's call the description, and then format it.

158
00:08:50,606 --> 00:08:54,773
And finally, we will yield the data points that we collected

159
00:08:56,129 --> 00:08:59,886
and see or test out if everything is working correctly,

160
00:08:59,886 --> 00:09:02,303
so let's copy and paste this.

161
00:09:03,229 --> 00:09:06,396
(typing and clicking)

162
00:09:15,744 --> 00:09:18,033
Let's speed this up a little bit,

163
00:09:18,033 --> 00:09:20,767
and this hopefully will work.

164
00:09:20,767 --> 00:09:21,767
I forgot to

165
00:09:22,870 --> 00:09:24,870
add the trailing quotes.

166
00:09:30,024 --> 00:09:31,521
And let's see if this is working,

167
00:09:31,521 --> 00:09:35,021
so we go and type in scrapy crawl books

168
00:09:37,215 --> 00:09:39,366
So it seems like everything is working correctly.

169
00:09:39,366 --> 00:09:43,033
Let's actually just go in once it's finished

170
00:09:44,206 --> 00:09:46,873
and output it to CSV file.

171
00:09:48,699 --> 00:09:50,400
And we can close it as of right now,

172
00:09:50,400 --> 00:09:53,305
so the item_scraped_count, because we closed it,

173
00:09:53,305 --> 00:09:54,888
is going to be 109.

174
00:09:56,532 --> 00:09:58,597
We open the items.csv, let's see

175
00:09:58,597 --> 00:10:01,848
if the image URL first and foremost is working.

176
00:10:01,848 --> 00:10:05,939
So it does, so the price is going to be selected

177
00:10:06,690 --> 00:10:09,357
and the rating is going to be the one.

178
00:10:09,357 --> 00:10:12,841
Description also seems to not have any junk characters

179
00:10:12,841 --> 00:10:17,008
and the title is going to be the title of the book,

180
00:10:17,109 --> 00:10:18,395
which is the correct one,

181
00:10:18,395 --> 00:10:21,776
so it seems like everything is working correctly.

182
00:10:21,776 --> 00:10:23,943
Let's close this CSV file.

183
00:10:25,455 --> 00:10:26,848
The very next data points,

184
00:10:26,848 --> 00:10:30,231
the last one that we're going to grab from each book URL

185
00:10:30,231 --> 00:10:34,148
is going to be product information data points.

186
00:10:35,441 --> 00:10:38,974
And this can be sort of abstracted

187
00:10:38,974 --> 00:10:42,208
by writing a function and then just calling that function

188
00:10:42,208 --> 00:10:45,256
and grabbing that data point.

189
00:10:45,256 --> 00:10:48,506
So let's actually go to our Scrapy code

190
00:10:50,002 --> 00:10:53,002
and call in the product information

191
00:10:55,420 --> 00:10:56,503
data points.

192
00:10:57,517 --> 00:11:01,350
The first one is going to be the upc.

193
00:11:01,350 --> 00:11:05,517
And let's actually first write our XPath

194
00:11:05,683 --> 00:11:07,766
that we are going to use.

195
00:11:08,781 --> 00:11:11,698
Let's see, the UPC is in the table.

196
00:11:12,558 --> 00:11:15,669
As you can see, it has the class "table-stripped."

197
00:11:15,669 --> 00:11:17,601
And then in the &lt;tbody&gt;,

198
00:11:17,601 --> 00:11:20,654
here we have all of the &lt;tr&gt;.

199
00:11:20,654 --> 00:11:21,756
In each &lt;tr&gt;,

200
00:11:21,756 --> 00:11:25,507
we have the &lt;th&gt;, and then &lt;td&gt;.

201
00:11:25,507 --> 00:11:29,589
Now, what we need to do is go into &lt;th&gt;

202
00:11:29,589 --> 00:11:32,868
that has the "UPC" string in it,

203
00:11:32,868 --> 00:11:37,035
and then follow the very next &lt;td&gt; instance,

204
00:11:37,051 --> 00:11:38,927
and this is going to be the value,

205
00:11:38,927 --> 00:11:42,219
or we select text from this &lt;td&gt;.

206
00:11:42,219 --> 00:11:43,748
Pretty simple.

207
00:11:43,748 --> 00:11:47,915
Let's actually go to our Scrapy Shell, response.xpath,

208
00:11:48,185 --> 00:11:49,185
and then...

209
00:11:50,432 --> 00:11:54,599
So we are going to select every &lt;th&gt;

210
00:11:54,813 --> 00:11:57,563
with the text that reads the "UPC".

211
00:11:59,802 --> 00:12:03,969
Let's see if this's working perfect and then we will follow,

212
00:12:04,473 --> 00:12:06,806
just like we did with the...

213
00:12:09,405 --> 00:12:11,373
just like we did in the description,

214
00:12:11,373 --> 00:12:13,039
we will use the following-sibling.

215
00:12:13,039 --> 00:12:15,563
And here, instead of the &lt;p&gt; tag,

216
00:12:15,563 --> 00:12:18,951
we are going to collect the &lt;td&gt;.

217
00:12:18,951 --> 00:12:23,118
So, following-sibling, and then type in the td,

218
00:12:23,525 --> 00:12:26,617
and then select text() from it.

219
00:12:26,617 --> 00:12:29,804
And then, finally, calling the extract_first().

220
00:12:29,804 --> 00:12:33,192
So as you can see, this is the value

221
00:12:33,192 --> 00:12:35,474
that corresponds to the UPC.

222
00:12:35,474 --> 00:12:39,641
If we, for example, typed in or just replaced here,

223
00:12:39,917 --> 00:12:41,750
the UPC with the Tax,

224
00:12:42,878 --> 00:12:47,045
as you will see in a moment, we are going to collect

225
00:12:49,357 --> 00:12:52,690
this data point, so it's going to be £0.

226
00:12:54,321 --> 00:12:58,488
Let's copy and paste this as of right now into our function.

227
00:12:58,523 --> 00:13:02,690
We haven't wrote function, so let's write it, finally.

228
00:13:03,173 --> 00:13:06,446
So def, and then we can type in,

229
00:13:06,446 --> 00:13:08,696
for example, product_info

230
00:13:10,648 --> 00:13:12,565
and then the arguments,

231
00:13:13,481 --> 00:13:17,648
or parameters, are going to be response, and then the value.

232
00:13:18,674 --> 00:13:21,841
And then we will return the statement,

233
00:13:23,810 --> 00:13:25,239
and let's see what needs to be changed.

234
00:13:25,239 --> 00:13:28,542
This is going to be modified, so this is going to be

235
00:13:28,542 --> 00:13:32,027
the value that we will additionally add.

236
00:13:32,027 --> 00:13:33,855
This, as of right now, should work,

237
00:13:33,855 --> 00:13:36,438
so let's go and test it in Shell.

238
00:13:37,475 --> 00:13:39,539
So if we type in product_info

239
00:13:39,539 --> 00:13:41,006
and then the first parameter

240
00:13:41,006 --> 00:13:43,224
is always going to be the response.

241
00:13:43,224 --> 00:13:46,502
And the value can be, for example, UPC.

242
00:13:46,502 --> 00:13:49,572
Perfect, it works well, let's try in the Tax.

243
00:13:49,572 --> 00:13:51,420
Perfect, it works well.

244
00:13:51,420 --> 00:13:52,752
Let's go to our code,

245
00:13:52,752 --> 00:13:56,919
and then type in the UPC, and then product_description.

246
00:13:57,551 --> 00:14:01,718
response, and then let's leave it as it is.

247
00:14:01,731 --> 00:14:04,674
And type in the rest of the data points

248
00:14:04,674 --> 00:14:06,323
that we're going to select.

249
00:14:06,323 --> 00:14:10,490
The second one is going to be product_type,

250
00:14:10,549 --> 00:14:12,745
and this is going to be the same.

251
00:14:12,745 --> 00:14:16,407
And the third one is going to be price without tax,

252
00:14:16,407 --> 00:14:17,490
so price_...

253
00:14:20,055 --> 00:14:22,555
without_tax is going to be

254
00:14:22,555 --> 00:14:23,722
equal to this.

255
00:14:26,263 --> 00:14:30,013
And the fourth is going to be price_with_tax.

256
00:14:35,028 --> 00:14:37,190
Let's see what else

257
00:14:37,190 --> 00:14:41,351
tax, availability, and number of reviews.

258
00:14:41,351 --> 00:14:42,184
So tax...

259
00:14:44,026 --> 00:14:47,193
(typing and clicking)

260
00:14:48,712 --> 00:14:51,629
And finally, let's see, number_...

261
00:14:53,605 --> 00:14:54,605
of_reviews.

262
00:15:00,037 --> 00:15:04,204
So there are going to be seven lines, or seven data points.

263
00:15:05,645 --> 00:15:09,024
One, two, three, four, five, six, seven, perfect.

264
00:15:09,024 --> 00:15:12,760
So the first one is going to be the UPC.

265
00:15:12,760 --> 00:15:16,343
The second one is going to be Product Type,

266
00:15:18,962 --> 00:15:23,129
and the type is going to be the uppercase.

267
00:15:23,145 --> 00:15:24,554
So, let's see, price excluding tax,

268
00:15:24,554 --> 00:15:28,721
maybe it's just going to be faster to copy and paste this.

269
00:15:30,734 --> 00:15:33,901
(clicking and typing)

270
00:15:38,560 --> 00:15:41,221
And there are going to be, as you saw,

271
00:15:41,221 --> 00:15:43,060
the white space trailing,

272
00:15:43,060 --> 00:15:47,227
but because there isn't really in the HTML page as it is,

273
00:15:47,725 --> 00:15:50,308
trailing white space, using it,

274
00:15:51,642 --> 00:15:53,642
it's not going to work.

275
00:15:55,696 --> 00:15:57,995
So tax is going to be Tax,

276
00:15:57,995 --> 00:16:00,995
and then availability is going to be

277
00:16:03,820 --> 00:16:05,751
this data point or string.

278
00:16:05,751 --> 00:16:09,918
And then finally, Number of reviews, copy and paste this.

279
00:16:12,988 --> 00:16:15,171
And we are going to be good to go.

280
00:16:15,171 --> 00:16:17,299
So the last thing that we need to do is

281
00:16:17,299 --> 00:16:21,346
just like we did in these five or so data points,

282
00:16:21,346 --> 00:16:25,179
just copy and paste this data points, then...

283
00:16:26,650 --> 00:16:29,900
to grab or put it into the dictionary.

284
00:16:32,186 --> 00:16:36,287
So, to do that, let's then just type in the upc,

285
00:16:36,287 --> 00:16:37,923
or actually, it's going to be easier

286
00:16:37,923 --> 00:16:40,173
just to copy and paste this

287
00:16:41,040 --> 00:16:41,957
as it is...

288
00:16:47,457 --> 00:16:49,414
This, for some reason, it's not going to work

289
00:16:49,414 --> 00:16:53,081
because last instance doesn't contain the...

290
00:16:54,647 --> 00:16:57,314
comma, so let's try it as it is.

291
00:16:59,698 --> 00:17:02,948
Perfect, and we need to add the quotes.

292
00:17:09,717 --> 00:17:13,227
I'm sure there is better way of doing this,

293
00:17:13,227 --> 00:17:14,644
to automate this.

294
00:17:15,517 --> 00:17:19,032
It should work, so let's actually try it out.

295
00:17:19,032 --> 00:17:22,615
As of right now, there are around 12 or so,

296
00:17:23,832 --> 00:17:27,999
12 data points that should be collected from every book URL.

297
00:17:28,305 --> 00:17:31,036
So let's see if this is working.

298
00:17:31,036 --> 00:17:33,513
It seems like something is not right.

299
00:17:33,513 --> 00:17:37,624
Let's see, product_description is not defined.

300
00:17:37,624 --> 00:17:40,874
Hmm, so let's see, product_description.

301
00:17:43,155 --> 00:17:45,822
product_info is going to be the

302
00:17:47,255 --> 00:17:48,790
name of the function.

303
00:17:48,790 --> 00:17:50,531
Let's try it as-is.

304
00:17:50,531 --> 00:17:53,749
And, seems like everything's working nicely.

305
00:17:53,749 --> 00:17:55,916
Let's try it once again...

306
00:17:58,914 --> 00:18:02,255
Let's close it in, and let's see if we get any errors.

307
00:18:02,255 --> 00:18:05,982
Perfect, so it seems like everything is working great.

308
00:18:05,982 --> 00:18:08,338
item_scraped_count is 215,

309
00:18:08,338 --> 00:18:11,171
so 200 or so book URLs are scraped

310
00:18:13,035 --> 00:18:14,236
and extracted

311
00:18:14,236 --> 00:18:17,696
are the data points that follow, so price,

312
00:18:17,696 --> 00:18:20,208
tax, tax is always going to be

313
00:18:20,208 --> 00:18:23,285
the same number for reviews also.

314
00:18:23,285 --> 00:18:26,685
availability, product_type, then title,

315
00:18:26,685 --> 00:18:29,195
upc, which is going to be different,

316
00:18:29,195 --> 00:18:32,827
price_with_tax and without_tax and the image_urls.

317
00:18:32,827 --> 00:18:36,373
So it seems like everything is scraped correctly,

318
00:18:36,373 --> 00:18:38,258
and that will be it for this video.

319
00:18:38,258 --> 00:18:41,049
In the very next one, we will talk about Scrapy arguments.

320
00:18:41,049 --> 00:18:41,882
Talk soon!

