<html>
                        <head>
                        <link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
                        <title>018 Avoid Getting Banned!</title>
                        </head>
                        <body>
                        <div class="container">
                        <div class="row">
                        <div class="col-md-10 col-md-offset-1">
                            <p class="lead"><div class="asset-container">
    <div class="asset-container__padding article-view">
        <div class="w3c-default">
            <p>It is very important to be careful while scraping websites; 
otherwise, you might be banned. Here are some tips to keep in mind while
 web scraping:</p>

<p><br></p>











<p>1- In the file settings.py activate the option <code>DOWNLOAD_DELAY</code> or you can do that manually in your code through sleeping a for a random number of seconds. If you use sleep and random, here is a codesnippet:<br></p>





<pre class="prettyprint linenums">from time import sleep
import random

# Your code here
...

sleep(random.randrange(1,3))</pre>











<p><br></p>





























<p>2- In the file settings.py activate the option <code>USER_AGENT</code> like the following, or any Chrome or Firefox user agent <a href="http://www.useragentstring.com/pages/useragentstring.php" rel="noopener noreferrer" target="_blank">here</a>. Defining a user agent let you look more like a browserused by a real person, not an automatic robot.</p>

























<p><code>USER_AGENT = "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:40.0) Gecko/20100101 Firefox/40.1"</code></p>



















<p><br></p>





<p>3- Find external proxies and rotate IP addresses while scraping. You can use the package <code>scrapy-proxies</code> for the purpose. https://github.com/aivarsk/scrapy-proxies
</p>







<p><br></p>

















<p>4- For professional work, consider using ScrapingHub.com to host your scrapers - it offers a free limited plan.</p>





















<p><br></p>

<p><strong>Recommendations Before Web Scraping:</strong></p>

<p> Before web scraping, it is highly recommended to search for an API for the website you want to get data from. Most large websites offer APIs to make data extraction a better experience for both parties. So try first to search Google for an API for the website; if you find one, you do not need to scrape it. APIs generate JSON objects which are very similar to Python dictionaries, and from which data can be extracted using the Python JSON library.</p>



<p> Before web scraping, it is highly recommended you read the Terms and Conditions of the website. Some websites clearly mention prohibiting web scraping without permission, or mention some legal or copyright aspects related to the use of its data.</p>



<p> Before web scraping, employ common sense! Some web scraping or other robot activities are obviously illegal if they cause any direct or indirect damage to the company owning data or its customers. It is a good idea to discuss the purpose of a web scraping project with your client before accepting it.</p>



<p> Before web scraping, prepare your code to be "polite": do not unnecessarily disable robots.txt of the website; space out your requests a bit so that you do not hammer the site's server; and it is better to run your spiders during off-peak traffic hours of the website.</p>
        </div>
    </div>
</div>
</p>
                        </div>
                        </div>
                        </div>
                        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
                        </body>
                        </html>