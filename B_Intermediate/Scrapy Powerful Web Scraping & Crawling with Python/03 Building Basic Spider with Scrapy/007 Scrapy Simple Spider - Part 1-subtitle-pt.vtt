WEBVTT FILE
Kind: captions
Language: pt

1
00:00:00.774 --> 00:00:03.252
Olá! Hoje nós vamos aprender

2
00:00:03.252 --> 00:00:06.644
como começar um projeto Scrapy, então vamos começar agora.

3
00:00:06.644 --> 00:00:10.115
A primeira coisa que você precisa fazer é abrir o Terminal,

4
00:00:10.115 --> 00:00:14.282
no meu caso, eu clico com o botão direito e seleciono "Open Terminal".

5
00:00:15.093 --> 00:00:18.648
E então, se nós maximizarmos a saída e digitarmos

6
00:00:18.648 --> 00:00:22.064
"scrapy", nós vamos ver um punhado de comandos.

7
00:00:22.064 --> 00:00:25.043
O primeiro deles é a versão do Scrapy.

8
00:00:25.043 --> 00:00:29.046
O segundo é, se houver algum projeto ativo,

9
00:00:29.046 --> 00:00:30.870
a mensagem seria diferente,

10
00:00:30.870 --> 00:00:33.814
claro, se nós estamos no nosso diretório raiz,

11
00:00:33.814 --> 00:00:36.897
ou seja, se criamos um projeto Scrapy.

12
00:00:38.131 --> 00:00:40.869
E a próxima mensagem é a maneira de utilizar.

13
00:00:40.869 --> 00:00:44.864
Nós sempre teremos que rodar o comando "scrapy" primeiro

14
00:00:44.864 --> 00:00:48.595
e então imprimir os comandos que queremos usar,

15
00:00:48.595 --> 00:00:50.779
opções, e finalmente, argumentos.

16
00:00:50.779 --> 00:00:54.089
Como você vai ver no decorrer desse curso, usar

17
00:00:54.089 --> 00:00:57.506
Scrapy é realmente fácil e simples.

18
00:00:58.890 --> 00:01:01.432
E então, vamos ver, a próxima coisa

19
00:01:01.432 --> 00:01:03.801
são os comandos disponíveis.

20
00:01:03.801 --> 00:01:05.949
Aqui nós temos um bando de comandos.

21
00:01:05.949 --> 00:01:07.926
O primeiro deles é "bench".

22
00:01:07.926 --> 00:01:10.311
Eu raramente uso esse comando para ser honesto,

23
00:01:10.311 --> 00:01:14.478
e ele é principalmente usado para mostrar, ou realmente

24
00:01:14.480 --> 00:01:18.647
descobrir qual a performance exata do seu código spider.

25
00:01:19.179 --> 00:01:22.388
A segunda coisa é o comando "fetch".

26
00:01:22.388 --> 00:01:25.475
Ele vai buscar a URL, como você pode ver,

27
00:01:25.475 --> 00:01:28.496
usando o Scrapy downloader ou, em outras palavras,

28
00:01:28.496 --> 00:01:32.019
ele vai simplesmente abrir a URL com Scrapy.

29
00:01:32.019 --> 00:01:34.005
A terceira é o "genspider".

30
00:01:34.005 --> 00:01:37.259
Esse vai ser usado... então ele vai gerar

31
00:01:37.259 --> 00:01:40.157
um novo spider com o template.

32
00:01:40.157 --> 00:01:43.124
Então o Scrapy tem um punhado de templates.

33
00:01:43.124 --> 00:01:46.207
E nós vamos usar o padrão,

34
00:01:47.076 --> 00:01:49.481
mas eles oferecem também um template de rastreamento

35
00:01:49.481 --> 00:01:53.417
para rastrear sites inteiros e depois imprimir

36
00:01:53.417 --> 00:01:56.342
todas as regras diferentes que você pode querer,

37
00:01:56.342 --> 00:01:59.796
ou as páginas que você quer rastrear.

38
00:01:59.796 --> 00:02:03.031
A quarta opção é "runspider".

39
00:02:03.031 --> 00:02:06.568
Esse vai ser coberto em um outro vídeo

40
00:02:06.568 --> 00:02:09.615
que vou gravar e ele é usado principalmente

41
00:02:09.615 --> 00:02:11.839
quando você tem alguns simples, talvez,

42
00:02:11.839 --> 00:02:13.844
projetos Scrapy e quando você gostaria

43
00:02:13.844 --> 00:02:17.011
de simplificar a estrutura Scrapy.

44
00:02:18.700 --> 00:02:20.598
O "settings", vai simplesmente imprimir

45
00:02:20.598 --> 00:02:22.270
as diferentes configurações Scrapy.

46
00:02:22.270 --> 00:02:26.437
"shell" é uma das mais conhecidas funcionalidades do Scrapy

47
00:02:28.087 --> 00:02:31.407
e ela vai ser muito usada quando

48
00:02:31.407 --> 00:02:35.574
nós desenvolvermos algum tipo de projeto Scrapy para testar,

49
00:02:35.736 --> 00:02:39.111
ou, sério, para ver se os pontos de dados estão ali

50
00:02:39.111 --> 00:02:42.840
e para testar nosso código, em geral, em pedaços pequenos

51
00:02:42.840 --> 00:02:45.833
e então copiar e colar a saída ou, sério,

52
00:02:45.833 --> 00:02:49.607
os comandos que escrevemos no nosso shell no código Scrapy.

53
00:02:49.607 --> 00:02:53.153
"startproject", esse vai ser discutido em um minuto

54
00:02:53.153 --> 00:02:55.226
e vai ser nosso primeiro comando

55
00:02:55.226 --> 00:02:58.202
que vamos digitar no Scrapy e isso vai,

56
00:02:58.202 --> 00:03:00.372
obviamente, esse comando serve

57
00:03:00.372 --> 00:03:04.395
para iniciar, ou criar, um novo projeto.

58
00:03:04.395 --> 00:03:06.571
Então se digitarmos "version",

59
00:03:06.571 --> 00:03:09.202
por exemplo, nós vamos ver que 

60
00:03:09.202 --> 00:03:11.702
vamos receber essa mensagem.

61
00:03:13.212 --> 00:03:17.212
Então a versão é 1.1.2 e então o último comando é o "view".

62
00:03:18.728 --> 00:03:22.649
E isso vai abrir a URL no navegador como visto pelo Scrapy.

63
00:03:22.649 --> 00:03:25.232
Isso vai ser muito usado.

64
00:03:26.328 --> 00:03:29.255
A razão que você poderia gostar de usar "view"

65
00:03:29.255 --> 00:03:32.454
é para descobrir o que, na verdade, o Scrapy vê.

66
00:03:32.454 --> 00:03:36.270
Então abrir URLs com Scrapy e com seu,

67
00:03:36.270 --> 00:03:39.437
por exemplo, Chrome, vai ser diferente,

68
00:03:40.400 --> 00:03:43.817
às vezes, especialmente quando usamos páginas com muito Javascript,

69
00:03:43.817 --> 00:03:45.201
lembre-se disso.

70
00:03:45.201 --> 00:03:49.276
Então se você for para o shell do Scrapy e testar,

71
00:03:49.276 --> 00:03:51.274
eu não sei, essa citação que você gosta,

72
00:03:51.274 --> 00:03:55.060
por exemplo, para extraí-la e o dado não está lá,

73
00:03:55.060 --> 00:03:57.973
mesmo que você tenha escrito vários seletores diferentes,

74
00:03:57.973 --> 00:04:01.083
então certifique-se de usar o comando "view" do Scrapy

75
00:04:01.083 --> 00:04:04.374
para descobrir se os dados estão realmente lá.

76
00:04:04.374 --> 00:04:08.541
Porque em páginas com muito Javascript, os dados não

77
00:04:09.422 --> 00:04:13.589
vão ser gerados às vezes ou vistos pelo Scrapy.

78
00:04:15.077 --> 00:04:16.443
É isso.

79
00:04:16.444 --> 00:04:19.635
Então a primeira coisa

80
00:04:19.635 --> 00:04:22.245
que vamos fazer, de verdade, é iniciar nosso projeto.

81
00:04:22.245 --> 00:04:25.179
E para fazer isso nós digitamos, ou primeiro

82
00:04:25.179 --> 00:04:27.611
vamos mudar nosso diretório para nosso Desktop

83
00:04:27.611 --> 00:04:31.778
para que você possa ver a pasta que o Scrapy vai gerar aqui.

84
00:04:32.331 --> 00:04:36.498
Para mudar o diretório, nós digitamos "cd Desktop".

85
00:04:37.526 --> 00:04:41.693
E aqui nós temos, ou atualmente, nós estamos no Desktop.

86
00:04:42.726 --> 00:04:44.660
E o primeiro comando, como estava dizendo,

87
00:04:44.660 --> 00:04:47.389
vai ser "scrapy", então você pode

88
00:04:47.389 --> 00:04:49.793
simplesmente copiar e colar esse comando.

89
00:04:49.793 --> 00:04:53.793
Então "scrapy startproject" e o comando ou opção

90
00:04:54.678 --> 00:04:58.845
que você quer usar é só o nome do spider

91
00:04:59.017 --> 00:05:03.184
que vai ser "quotes_spider", por exemplo.

92
00:05:03.773 --> 00:05:05.867
Pressione Enter e você verá a mensagem

93
00:05:05.867 --> 00:05:08.666
de que o projeto foi criado e que

94
00:05:08.666 --> 00:05:12.272
podemos iniciar ou criar nosso primeiro spider

95
00:05:12.272 --> 00:05:15.713
primeiro mudando nosso diretório para quotes_spider.

96
00:05:15.713 --> 00:05:19.880
Então nessa pasta, e então finalmente, estou gerando meu spider.

97
00:05:20.126 --> 00:05:23.056
Então vamos navegar para quotes_spider.

98
00:05:23.056 --> 00:05:26.471
Se nós copiarmos e colarmos esse comando, e digitar Enter,

99
00:05:26.471 --> 00:05:30.359
nós vamos ver que atualmente nós estamos em quotes_spider.

100
00:05:30.359 --> 00:05:33.112
E se nós formos para a pasta e, por exemplo,

101
00:05:33.112 --> 00:05:36.983
voltar para nosso Terminal e digitar agora "scrapy"

102
00:05:36.983 --> 00:05:40.983
você vai ver que nós temos o projeto quotes_spider

103
00:05:42.127 --> 00:05:45.635
onde, anteriormente, não tínhamos projetos ativos.

104
00:05:45.635 --> 00:05:47.818
E o jeito de descobrir

105
00:05:47.818 --> 00:05:51.736
que você está no diretório raiz é olhando

106
00:05:51.736 --> 00:05:54.819
onde o arquivo .cfg ou o scrapy.cfg está.

107
00:05:56.317 --> 00:06:00.475
E esse é o arquivo de configuração que o Scrapy,

108
00:06:01.326 --> 00:06:04.326
por padrão, vai criar.

109
00:06:04.390 --> 00:06:06.022
E isso vai ser discutido um pouco

110
00:06:06.022 --> 00:06:08.134
depois com um pouco mais detalhes.

111
00:06:08.134 --> 00:06:11.042
A próxima coisa que o Scrapy vai gerar é

112
00:06:11.042 --> 00:06:15.209
a pasta que vai ser o nome do spider.

113
00:06:15.466 --> 00:06:18.525
E então nós temos um punhado de arquivos diferentes,

114
00:06:18.525 --> 00:06:20.744
como você pode ver, e esses ainda vão ser

115
00:06:20.744 --> 00:06:24.152
discutidos com mais detalhes depois.

116
00:06:24.152 --> 00:06:27.913
__init__.py, items.py, pipelines.py e settings.py

117
00:06:27.913 --> 00:06:31.530
Esses são relativamente simples e benéficos

118
00:06:31.530 --> 00:06:34.170
para qualquer momento que você queira criar

119
00:06:34.170 --> 00:06:37.561
alguns spiders Scrapy mais complexos,

120
00:06:37.561 --> 00:06:39.552
especialmente o arquivo settings.py,

121
00:06:39.552 --> 00:06:42.272
como você vai ver ao longo desse curso.

122
00:06:42.272 --> 00:06:46.439
E os "spiders" vão ser a última coisa que vamos abordar aqui.

123
00:06:47.193 --> 00:06:49.824
E "spiders" é somente uma pasta e aqui

124
00:06:49.824 --> 00:06:53.300
nós não temos nenhum tipo de, sério,

125
00:06:53.300 --> 00:06:57.409
arquivos ou arquivos de spider, arquivos python, nada.

126
00:06:57.409 --> 00:07:00.697
Nós só temos o __init__.py, então se abrirmos ele

127
00:07:00.697 --> 00:07:03.394
com nosso editor de textos favorito, você vai ver que

128
00:07:03.394 --> 00:07:07.561
ele está só vazio ou comentado com suas sentenças

129
00:07:09.043 --> 00:07:12.128
que é praticamente nada, certo?

130
00:07:12.128 --> 00:07:16.295
Para gerar um spider, nós vamos voltar para o Terminal

131
00:07:16.514 --> 00:07:20.640
e então digitar "scrapy" e então "genspider" para

132
00:07:20.640 --> 00:07:24.767
gerar um novo spider usando templates pré-definidos.

133
00:07:24.767 --> 00:07:27.344
Então copie e cole esse comando.

134
00:07:27.344 --> 00:07:30.713
E então as duas opções, ou argumentos,

135
00:07:30.713 --> 00:07:34.880
que nós precisamos colocar são: primeiro o nome do spider.

136
00:07:35.751 --> 00:07:39.560
Então vamos dizer que nós queremos nomeá-lo como "quotes",

137
00:07:39.560 --> 00:07:42.654
e a segunda coisa é o domínio

138
00:07:42.654 --> 00:07:45.839
que nós vamos extrair, ou o site.

139
00:07:45.839 --> 00:07:48.401
Para isso nós vamos para o Chrome

140
00:07:48.401 --> 00:07:51.422
e então copiamos e colamos

141
00:07:51.422 --> 00:07:54.899
esse site que gostaríamos de extrair.

142
00:07:54.899 --> 00:07:58.899
Cole aqui e, vamos remover a parte do http,

143
00:08:00.364 --> 00:08:02.912
e então vamos só pressionar Enter, sério.

144
00:08:02.912 --> 00:08:07.079
Como você pode ver, nós recebemos a mensagem de que o spider foi criado.

145
00:08:07.083 --> 00:08:10.098
E se nós formos para a pasta do spider, você pode ver

146
00:08:10.098 --> 00:08:14.064
que o quotes.py vai ser gerado.

147
00:08:14.064 --> 00:08:17.354
Então se você abrir ele com um editor de texto, você verá

148
00:08:17.354 --> 00:08:20.801
que o codigo vai ser...

149
00:08:20.801 --> 00:08:23.090
esse vai ser o código padrão que o Scrapy

150
00:08:23.090 --> 00:08:26.411
vai gerar automaticamente para templates padrão

151
00:08:26.411 --> 00:08:28.237
que nós, nesse caso, usamos.

152
00:08:28.237 --> 00:08:31.842
Então vamos, por exemplo, gerar um outro.

153
00:08:31.842 --> 00:08:34.509
Então "scrapy", "genspider" e "example"

154
00:08:36.607 --> 00:08:39.858
e vamos usar "example.com" como o domínio.

155
00:08:39.858 --> 00:08:42.593
Pressione Enter e se nós digitamos, por exemplo,

156
00:08:42.593 --> 00:08:45.751
"scrapy list", então esse comando, como você pode ver,

157
00:08:45.751 --> 00:08:48.726
vai listar todos os spiders disponíveis.

158
00:08:48.726 --> 00:08:51.479
Você verá que nós temos duas linhas,

159
00:08:51.479 --> 00:08:54.093
ou seja, dois spiders diferentes.

160
00:08:54.093 --> 00:08:56.982
Então "scrapy list", pressione Enter e você verá

161
00:08:56.982 --> 00:08:59.492
que nós temos "example" e "quotes".

162
00:08:59.492 --> 00:09:02.607
Se nós voltarmos para a pasta nós veremos

163
00:09:02.607 --> 00:09:06.048
que na pasta do spider, nós temos agora example.py,

164
00:09:06.048 --> 00:09:10.112
o arquivo __init__.py, que estava inicialmente aqui,

165
00:09:10.112 --> 00:09:12.120
e também o arquivo quotes.py.

166
00:09:12.120 --> 00:09:14.744
Então se nós abrirmos o example.py você verá

167
00:09:14.744 --> 00:09:18.911
que o código será basicamente o mesmo.

168
00:09:19.304 --> 00:09:22.033
O nome da classe vai ser diferente e também

169
00:09:22.033 --> 00:09:25.154
o nome do spider e todos os domínios e URLs iniciais

170
00:09:25.154 --> 00:09:27.797
vão ser diferentes, enquanto todo o resto lógico,

171
00:09:27.797 --> 00:09:31.898
como o nome de métodos e funções, vão ser o mesmo.

172
00:09:31.898 --> 00:09:35.164
E isso é tudo para este vídeo.

173
00:09:35.164 --> 00:09:38.115
No próximo vídeo, nós vamos

174
00:09:38.115 --> 00:09:41.596
começar a extrair algo de verdade

175
00:09:41.596 --> 00:09:44.846
nesse arquivo. Então fiquem ligados.
