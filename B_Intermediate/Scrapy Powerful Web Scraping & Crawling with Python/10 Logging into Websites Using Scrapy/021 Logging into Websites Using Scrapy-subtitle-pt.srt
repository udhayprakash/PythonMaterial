1
00:00:00,506 --> 00:00:02,867
Olá! Neste vídeo, vamos aprender

2
00:00:02,867 --> 00:00:06,123
como logar no site com Scrapy, e vamos fazer isso

3
00:00:06,123 --> 00:00:08,534
com o código existente que nós temos

4
00:00:08,534 --> 00:00:10,275
do nosso vídeo anterior.

5
00:00:10,275 --> 00:00:14,221
Então vamos verificar novamente se tudo está

6
00:00:14,221 --> 00:00:17,439
funcionando corretamente e sem nenhum erro.

7
00:00:17,439 --> 00:00:20,739
Tudo está funcionando bem, então praticamente todo este site,

8
00:00:20,739 --> 00:00:23,140
desde a página inicial, tem o botão de Login.

9
00:00:23,140 --> 00:00:26,765
Após isso, vamos para a página /login,

10
00:00:26,765 --> 00:00:30,057
e nós podemos digitar qualquer combinação de usuário e senha

11
00:00:30,057 --> 00:00:34,225
e digitar Login, e nós seremos redirecionados

12
00:00:35,720 --> 00:00:39,887
para a página inicial e aqui nós temos o botão Logout,

13
00:00:40,073 --> 00:00:42,240
e isso tudo significa

14
00:00:42,240 --> 00:00:44,851
que nós conseguimos logar com sucesso.

15
00:00:44,851 --> 00:00:48,554
Obviamente, esse é somente um site de demonstração e, no site real,

16
00:00:48,554 --> 00:00:52,234
após realizar o login, você consegue alguns pontos de dados, URLs,

17
00:00:52,234 --> 00:00:56,401
ou coisas como essa que você não tem normalmente

18
00:00:56,948 --> 00:00:59,640
sem se logar, então esse é o ponto

19
00:00:59,640 --> 00:01:03,524
de realmente utilizar o login.

20
00:01:04,203 --> 00:01:08,370
Então vamos voltar para o Firefox, o bom e velho Firefox,

21
00:01:08,468 --> 00:01:12,585
e vamos simplesmente ir para o Login.

22
00:01:12,585 --> 00:01:15,335
E agora nós podemos ir para o Firebug.

23
00:01:16,200 --> 00:01:19,620
E, agora, para o Net developer tools.

24
00:01:19,620 --> 00:01:22,998
E, como você pode ver no pop-up, ele nos permite analisar

25
00:01:22,998 --> 00:01:25,248
o tráfego da rede ou URLs

26
00:01:26,871 --> 00:01:30,430
que o servidor está requisitando.

27
00:01:31,021 --> 00:01:33,271
Agora, temos duas requisições.

28
00:01:34,159 --> 00:01:38,305
A primeira delas, nesse caso temos duas delas.

29
00:01:38,305 --> 00:01:40,486
A primeira delas será o POST,

30
00:01:40,486 --> 00:01:43,495
e a segunda delas será o GET.

31
00:01:43,495 --> 00:01:46,828
Então vamos só clicar no Login, e aqui,

32
00:01:49,049 --> 00:01:53,215
como você provavelmente consegue ver, agora nós temos o POST e o GET.

33
00:01:53,606 --> 00:01:55,951
POST vai ser o mais interessante deles,

34
00:01:55,951 --> 00:01:58,254
e aqui nós temos os status.

35
00:01:58,254 --> 00:02:01,620
E esse é o 302 que quer dizer

36
00:02:01,620 --> 00:02:05,694
que nós fomos redirecionados e do login na página,

37
00:02:06,968 --> 00:02:09,270
então aqui nós fomos redirecionados

38
00:02:09,270 --> 00:02:11,864
uma vez que estamos logados na página inicial.

39
00:02:11,864 --> 00:02:16,031
Isso quer dizer que a outra URL é essa

40
00:02:16,925 --> 00:02:19,433
depois do redirecionamento, assim falando,

41
00:02:19,433 --> 00:02:22,115
e nós estamos indo para a página inicial.

42
00:02:22,115 --> 00:02:24,043
Nós não ligamos muito para essa página.

43
00:02:24,043 --> 00:02:27,770
Nós só ligamos para a requisição POST.

44
00:02:27,770 --> 00:02:30,979
Então vamos simplesmente maximizar isso um pouco.

45
00:02:30,979 --> 00:02:34,229
E depois de aparecer isso, nós vamos ver

46
00:02:35,554 --> 00:02:38,394
que tem mais do que algumas abas.

47
00:02:38,394 --> 00:02:41,605
Principalmente, nós estamos interessados nesse Post,

48
00:02:41,605 --> 00:02:43,377
então aqui nós temos três argumentos.

49
00:02:43,377 --> 00:02:46,745
O primeiro deles é o csrf_token.
50

50
00:02:46,745 --> 00:02:49,526
Esse daqui vai ser o token que vai mudar dinamicamente,

51
00:02:49,526 --> 00:02:53,228
e isso vai ser definitivamente importante para nós

52
00:02:53,228 --> 00:02:56,570
porque sem isso não vamos conseguir logar no site

53
00:02:56,570 --> 00:02:58,144
de forma bem sucedida.

54
00:02:58,144 --> 00:03:01,764
E finalmente nós podemos ter essa combinação de

55
00:03:01,764 --> 00:03:05,828
senha e usuário escritos de forma literal no nosso código.

56
00:03:05,828 --> 00:03:09,995
Eles não importam de verdade, eles não podem ser modificados

57
00:03:10,818 --> 00:03:14,068
e eles não são dinamicamente especificados

58
00:03:14,068 --> 00:03:16,651
como essa string ou esse token.

59
00:03:17,931 --> 00:03:20,574
Então vamos voltar para o nosso código.

60
00:03:20,574 --> 00:03:22,957
Então no seu código, o que precisa ser atualizado

61
00:03:22,957 --> 00:03:24,894
é, primeiramente, os imports.

62
00:03:24,894 --> 00:03:29,061
Então o import que nos vamos usar é esse submódulo

63
00:03:29,121 --> 00:03:31,449
do Scrapy chamado FormRequest.

64
00:03:31,449 --> 00:03:34,206
Então nós podemos importar isso digitando

65
00:03:34,206 --> 00:03:38,348
"from scrapy.http import FormRequest",

66
00:03:39,924 --> 00:03:44,091
vamos ver, e vamos usar isso em um momento.

67
00:03:44,183 --> 00:03:47,194
Então a URL inicial não vai ser essa.

68
00:03:47,194 --> 00:03:50,191
Nós também não precisamos do allowed_domains.

69
00:03:50,191 --> 00:03:53,112
Isso vai fazer as coisas ficarem complicadas

70
00:03:53,112 --> 00:03:55,362
sem nenhum efeito positivo.

71
00:03:59,289 --> 00:04:01,721
A página inicial não vai ser a URL inicial.

72
00:04:01,721 --> 00:04:05,763
Vai ser essa daqui, então isso vai...

73
00:04:05,763 --> 00:04:07,680
Vamos refazer isso na verdade.

74
00:04:08,927 --> 00:04:12,344
A URL inicial vai ser essa aqui.

75
00:04:14,371 --> 00:04:18,120
Vamos ver... Então vamos só renomear isso

76
00:04:19,374 --> 00:04:22,290
para alguma coisa como scrape_home_page,

77
00:04:23,240 --> 00:04:26,740
e então a função, a função padrão,

78
00:04:26,740 --> 00:04:29,288
vai ser, claro, o parse

79
00:04:29,288 --> 00:04:33,194
e ela vai apenas ler todas as respostas

80
00:04:33,194 --> 00:04:37,125
e, claro, vai ser lido a partir dessa página.

81
00:04:37,125 --> 00:04:40,958
E, finalmente, nós vamos usar o "yield Request"

82
00:04:42,516 --> 00:04:46,682
ou retornar ele, mas antes disso, nós temos que pegar

83
00:04:50,990 --> 00:04:52,240
o csrf_token.

84
00:04:53,770 --> 00:04:57,937
Ele está localizado aqui na página Login então vamos inspecioná-lo

85
00:04:58,252 --> 00:05:02,419
com o Google, e aqui nós temos ele no nó &lt;input&gt;.

86
00:05:02,767 --> 00:05:06,934
Como a página é apenas uma demonstração, podemos

87
00:05:08,882 --> 00:05:13,049
identificar neste momento qual exatamente é o valor

88
00:05:14,431 --> 00:05:16,695
que estamos procurando e, neste caso,

89
00:05:16,695 --> 00:05:18,649
ele vai ser esta string.

90
00:05:18,649 --> 00:05:21,200
Se recarregarmos esta página, ele vai ser,

91
00:05:21,200 --> 00:05:24,486
como você verá em um momento, ele será algo completamente

92
00:05:24,486 --> 00:05:26,586
diferente, como você pode ver.

93
00:05:26,586 --> 00:05:29,288
Então ele é um valor dinamicamente mudado

94
00:05:29,288 --> 00:05:31,655
porque, depois de tudo, ele é um token.

95
00:05:31,655 --> 00:05:35,563
Então aqui nós temos no nó HTML &lt;input&gt;.

96
00:05:36,945 --> 00:05:40,721
Nós temos o valor, mas vamos pegar ele

97
00:05:40,721 --> 00:05:44,049
com o nome e então no nome nós vamos

98
00:05:44,049 --> 00:05:47,709
olhar exatamente para esta string, e então dele

99
00:05:47,709 --> 00:05:49,435
nós podemos extrair o valor.

100
00:05:49,435 --> 00:05:53,466
Então para não desperdiçar mais tempo, vamos para o

101
00:05:53,466 --> 00:05:55,775
scrapy shell e então testar

102
00:05:55,775 --> 00:05:59,068
se podemos extrair o dado de lá.

103
00:05:59,068 --> 00:06:02,735
Então response.xpath e vamos ver. Vamos

104
00:06:04,055 --> 00:06:08,222
pegar o nome mais uma vez que é do input.

105
00:06:09,742 --> 00:06:13,358
Mas não nos importamos então vamos extrair o nome

106
00:06:13,358 --> 00:06:17,192
com o valor csrf_token,

107
00:06:17,504 --> 00:06:19,441
e aqui achamos um Selector.

108
00:06:19,441 --> 00:06:22,858
Então vamos apenas pegar o nó HTML.

109
00:06:24,491 --> 00:06:26,661
Então ele está na forma de uma lista.

110
00:06:26,661 --> 00:06:30,078
Então isso é bom, e aqui nós temos a parte HTML

111
00:06:31,341 --> 00:06:35,508
do &lt;input&gt; e o valor vai ser o que precisamos.

112
00:06:36,440 --> 00:06:39,404
Então nós precisamos este tipo de dado,

113
00:06:39,404 --> 00:06:42,987
e para extrair o valor, nós vamos apenas

114
00:06:43,897 --> 00:06:48,056
digitar "/@value".

115
00:06:49,818 --> 00:06:53,757
E isto está na forma de uma lista então para conseguir o unicode

116
00:06:53,757 --> 00:06:57,715
vamos apenas digitar "extract_first()".

117
00:06:57,715 --> 00:07:01,355
Então vamos copiar isso, vamos voltar para nosso código,

118
00:07:01,355 --> 00:07:05,510
e vamos chamar esta variável como token.

119
00:07:05,510 --> 00:07:09,107
Então vamos deixar isto um pouco mais bonito, mais legível

120
00:07:09,107 --> 00:07:13,274
e finalmente eu acho que podemos usar "return FormRequest".

121
00:07:16,001 --> 00:07:19,256
Agora isso vai ler da página Login então vamos usar

122
00:07:19,256 --> 00:07:22,188
from_response, então para fazer isso

123
00:07:22,188 --> 00:07:26,346
vamos usar esta sintaxe.

124
00:07:27,538 --> 00:07:30,756
E vamos ver, então o primeiro parâmetro aqui

125
00:07:30,756 --> 00:07:32,482
vai ser a URL.

126
00:07:32,482 --> 00:07:36,227
Nós podemos apenas ler do response e então nós

127
00:07:36,227 --> 00:07:38,602
colocamos formdata,

128
00:07:40,301 --> 00:07:41,507
vamos ver, formdata.

129
00:07:41,507 --> 00:07:44,677
Então formdata vai ser apenas um dicionário,

130
00:07:44,677 --> 00:07:46,812
e nesse dicionário vai ter apenas

131
00:07:46,812 --> 00:07:49,404
três itens de dicionário.

132
00:07:49,404 --> 00:07:51,504
O primeiro deles vai ser basicamente isto,

133
00:07:51,504 --> 00:07:55,671
e os últimos dois vão ser a senha e o usuário.

134
00:07:56,073 --> 00:07:59,275
Então vamos definir primeiro as chaves do dicionário.

135
00:07:59,275 --> 00:08:02,692
Então o primeiro deles vai ser este aqui,

136
00:08:04,637 --> 00:08:07,310
então formdata vai ser este aqui.

137
00:08:07,310 --> 00:08:10,186
E este aqui ou o primeiro vai obviamente ler

138
00:08:10,186 --> 00:08:13,183
do token, então ele vai ser

139
00:08:13,183 --> 00:08:15,733
dinamicamente mudado.

140
00:08:15,733 --> 00:08:18,385
O segundo vai ser o password.

141
00:08:18,385 --> 00:08:22,552
Não importa se você colocar a senha primeiro e então,

142
00:08:22,828 --> 00:08:25,490
por exemplo, o csrf_token.

143
00:08:25,490 --> 00:08:29,657
A lista não está ordenada e o último será o username.

144
00:08:30,508 --> 00:08:34,675
Então podemos digitar literalmente e colocar qualquer coisa aqui.

145
00:08:35,485 --> 00:08:39,318
Não importa, como você verá em um momento.

146
00:08:40,339 --> 00:08:44,272
E vamos ver, e precisamos ainda ter o callback.

147
00:08:46,435 --> 00:08:49,650
Então para fazer isso ou chamar a função callback,

148
00:08:49,650 --> 00:08:52,766
para fazer isso digite "callback" que vai ser igual

149
00:08:52,766 --> 00:08:56,025
ao self.scrape_home_page.

150
00:08:56,383 --> 00:09:00,430
Então ele vai para esta página e então extrair o dado.

151
00:09:01,280 --> 00:09:03,625
Vamos ver se estou esquecendo algo.

152
00:09:03,625 --> 00:09:06,958
Eu não acho que estou, mas vamos verificar.

153
00:09:08,073 --> 00:09:12,240
Parece que tudo está na ordem certa,

154
00:09:12,380 --> 00:09:16,547
então vamos voltar para nosso código spider e vamos rodar ele.

155
00:09:20,610 --> 00:09:22,095
E parece que ele está funcionando.

156
00:09:22,095 --> 00:09:25,804
Então para ter certeza que está realmente funcionando,

157
00:09:25,804 --> 00:09:29,222
o que precisamos fazer é chamar outro import.

158
00:09:29,222 --> 00:09:33,389
E este import é também um módulo no módulo Scrapy,

159
00:09:34,485 --> 00:09:38,592
e ele é chamado open_in_browser, então vamos importá-lo.

160
00:09:38,592 --> 00:09:42,717
Então "from scrapy.utils.response import

161
00:09:46,093 --> 00:09:50,234
open_in_browser".

162
00:09:51,471 --> 00:09:54,019
E então podemos apenas ir para a função

163
00:09:54,019 --> 00:09:56,035
chamada scrape_home_page e apenas

164
00:09:56,035 --> 00:09:58,577
"open_in_browser(response)".

165
00:09:58,577 --> 00:10:02,535
Clicar Save e isto é usado normalmente quando depurar.

166
00:10:02,535 --> 00:10:06,594
Então se você não sabe que tipo de página

167
00:10:07,754 --> 00:10:10,924
está sendo carregada, você pode então abrir

168
00:10:10,924 --> 00:10:12,817
no navegador com a função.

169
00:10:12,817 --> 00:10:16,954
Por exemplo, ver o que exatamente ou quais pontos de dados

170
00:10:16,954 --> 00:10:20,908
estão disponíveis porque às vezes como mais e mais sites

171
00:10:20,908 --> 00:10:25,075
são cheios de Javascript, às vezes os pontos de dados são lidos

172
00:10:26,451 --> 00:10:30,618
de alguma URL ou algo como isso do lado do servidor.

173
00:10:30,936 --> 00:10:33,815
Vamos ver, vamos rodar ele na verdade e isto vai

174
00:10:33,815 --> 00:10:37,982
abrir o arquivo tmp, como você verá em um momento.

175
00:10:38,587 --> 00:10:40,087
Então esta é a URL

176
00:10:42,720 --> 00:10:45,351
ou é lido do response, certo,

177
00:10:45,351 --> 00:10:46,543
então vamos apenas rodá-lo

178
00:10:46,543 --> 00:10:48,337
e você verá em um momento, perfeito.

179
00:10:48,337 --> 00:10:52,504
Então ele está aberto e aqui da página inicial nós temos o botão

180
00:10:53,731 --> 00:10:56,738
de Logout o que significa que estamos logados.

181
00:10:56,738 --> 00:11:00,905
Então se formos para a página inicial, você pode ver,

182
00:11:01,084 --> 00:11:03,673
este é o, novamente da Internet,

183
00:11:03,673 --> 00:11:07,127
então não estamos logados aqui e do tmp

184
00:11:07,127 --> 00:11:10,785
ou do arquivo temporário, estamos logados.

185
00:11:11,330 --> 00:11:14,290
Então isso significa que nós estamos prontos para continuar

186
00:11:14,290 --> 00:11:17,672
e que nosso login funcionou perfeitamente bem.

187
00:11:17,672 --> 00:11:20,146
Novamente, isto é apenas para propósito de demonstração.

188
00:11:20,146 --> 00:11:23,962
Você poderia logar em sites reais de forma similar

189
00:11:23,962 --> 00:11:26,429
ou exatamente como isso.

190
00:11:26,429 --> 00:11:30,596
Na maioria do tempo o site vai ter algum tipo de token

191
00:11:31,448 --> 00:11:33,588
e essa senha e usuário, claro,

192
00:11:33,588 --> 00:11:37,755
você vai definir quando você se registrar e isso deve

193
00:11:37,810 --> 00:11:40,283
ser tudo para este vídeo.

194
00:11:40,283 --> 00:11:43,740
No próximo nós vamos falar mais sobre como você pode

195
00:11:43,740 --> 00:11:47,907
rodar o spider Scrapy sem precisar definir a árvore do

196
00:11:48,165 --> 00:11:52,332
projeto inteiro como fizemos aqui, então você pode rodar ele

197
00:11:52,560 --> 00:11:55,393
com "python foo.py".

198
00:11:56,465 --> 00:11:59,269
Então vejo você no próximo vídeo!

