<html>
                        <head>
                        <link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
                        <title>036 Craigslist Scrapy Spider #1 8O Titles</title>
                        </head>
                        <body>
                        <div class="container">
                        <div class="row">
                        <div class="col-md-10 col-md-offset-1">
                            <p class="lead"><div class="asset-container">
    <div class="asset-container__padding article-view">
        <div class="w3c-default">
            <p>If you are new to Scrapy, lets start by extracting and retrieving only one element for the sake of clarification. Otherwise, you may skip this lecture to the next one, or read it quickly for revision.</p>

<p>We are just starting with this basic spider as a foundation for more sophisticated spiders in this Scrapy tutorial. This simple spider will only extract job titles.<br></p>

















































<h4></h4><h4>Editing the parse() Function</h4>















































<p>Instead of pass, add this line to the parse() function:</p>

















































<p><code>titles = response.xpath('//a[@class="result-title hdrlnk"]/text()').extract()</code><br></p>













































<p><strong><br></strong></p><p><strong>What does this mean?</strong></p><p><code>titles</code> is a [list] of text portions extracted based on a rule.</p>

















































<p><code>response</code> is simply the whole html source code retrieved from the page. Actually, response has a deeper meaning because if you print(response) you will get something like &lt;200 https://newyork.craigslist.org/search/egr&gt; which means you have managed to connect to this web page; however, if you print(response.body) you will get the whole source code. Anyhow, when you use XPath expressions to extract HTML nodes, you should directly use response.xpath()</p>

















































<p><code>xpath</code> is how we will extract portions of text and it has rules. XPath is a detailed topic and we will dedicate a separate article for it. But generally try to notice the following:</p>

















































<p>Open the URL in your browser, move the cursor on any job title, right-click, and select Inspect. You can see now the HTML code like this:</p>

















































<p><code>&lt;a href="/brk/egr/6085878649.html" data-id="6085878649" class="result-title hdrlnk"&gt;Chief Engineer&lt;/a&gt;</code><br>So, you want to extract Chief Engineer which is the text of an &lt;a&gt; tag, and as you can see this &lt;a&gt; tag has the class result-title hdrlnk which can distinguish it from other &lt;a&gt; tags on the web-page.</p>

















































<p><strong><br></strong></p>































<p><strong>Lets explain the XPath rule we have:</strong></p>

















































<p><code>//</code> means instead of starting from the &lt;html&gt;, just start from the tag that I will specify after it.</p>

















































<p><code>/a</code> simply refers to the &lt;a&gt; tag.</p>

















































<p><code>[@class="result-title hdrlnk"]</code> that is directly comes after /a means the &lt;a&gt; tag must have this class name in it.</p>

















































<p><code>text()</code> refers to the text of the &lt;a&gt; tag, which isChief Engineer.</p>

















































<p><code>extract()</code> means extract every instance on the web page that follows the same XPath rule into a [list].</p>

















































<p><code>extract_first()</code> if you use it instead of extract() it will extract only the first item in the list.</p>



















































<p><br></p>























<p>Now, you can print titles:</p>























<p><code>print(titles)</code><br></p>



















































<p>Your basic Scrapy spider code should now look like this:<br></p>























<pre class="prettyprint linenums"># -*- coding: utf-8 -*-
import scrapy

class JobsSpider(scrapy.Spider):
    name = "jobs"
    allowed_domains = ["craigslist.org"]
    start_urls = ['https://newyork.craigslist.org/search/egr']

    def parse(self, response):
        titles = response.xpath('//a[@class="result-title hdrlnk"]/text()').extract()
        print(titles)</pre>

































































































<h4><br>Running the Scrapy Spider</h4>

















































<p>Now, move to your Terminal, make sure you are in the root directory of your Scrapy project craigslist and run the spider using the following command:</p>

















<p><code>scrapy crawl jobs</code> <br></p>



















































<p>In Terminal, you will get a similar result; it is a [list] including the job titles (the titles can vary from day to day):</p>

















































<p><code>[u'Junior/ Mid-Level  Architect for Immediate Hire', u'SE BUSCA LLANTERO/ LOOKING FOR TIRE CAR WORKER CON EXPERIENCIA', u'Draftsperson/Detailer', u'Controls/ Instrumentation Engineer', u'Project Manager', u'Tunnel Inspectors - Must be willing to Relocate to Los Angeles', u'Senior Designer - Large Scale', u'Construction Estimator/Project Manager', u'CAD Draftsman/Estimator', u'Project Manager']</code></p>

















































<p>As you can see, the result is a list of Unicode strings. So you can loop on them, and yield one title per time in a form of dictionary.<br></p>





















<pre class="prettyprint linenums">for title in titles:
    yield {'Title': title}</pre>











































<p><br></p>

















































<p>Your basic Scrapy spider code should now look like this:</p><pre class="prettyprint linenums"># -*- coding: utf-8 -*-
import scrapy

class JobsSpider(scrapy.Spider):
    name = "jobs"
    allowed_domains = ["craigslist.org"]
    start_urls = ['https://newyork.craigslist.org/search/egr']

    def parse(self, response):
        titles = response.xpath('//a[@class="result-title hdrlnk"]/text()').extract()
        for title in titles:
            yield {'Title': title}</pre>



































































<h4></h4><h4>Storing the Scraped Data to CSV</h4>

















































<p>You can now run your spider and store the output data into CSV, JSON or XML. To store the data into CSV, run the following command in Terminal. The result will be a CSV file called result-titles.csv in your Scrapy spider directory.</p>













<p><code>scrapy crawl jobs -o result-titles.csv</code><br></p>











<p>Your Terminal should show you a similar result, which indicates success.</p>









<pre class="prettyprint linenums">'downloader/response_status_count/200': 2,
'finish_reason': 'finished',
'finish_time': datetime.datetime(2017, 5, 2, 17, 26, 30, 348412),
'item_scraped_count': 120,
'log_count/DEBUG': 123,
'log_count/INFO': 8,</pre>

























<p><br></p>

















































<p><code>'item_scraped_count'</code> refers to the number of titles scraped from the page. <code>'log_count/DEBUG' </code> and <code>'log_count/INFO'</code> are okay; however, if you received <code>'log_count/ERROR'</code> you should find out which errors you get during scraping are fix your code.</p>

















































<p>In Terminal, you will notice debug messages like:</p>







<p><code>DEBUG: Scraped from &lt;200 https://newyork.craigslist.org/search/egr&gt;</code><br><br></p>

















































<p>The status code 200 means the request has succeeded. Also, 'downloader/response_status_count/200' tells you how many requests succeeded. There are many other status codes with different meanings; however, in web scraping they could act as a defense mechanism against web scraping.</p>







<p><br></p>
        </div>
    </div>
</div>
</p>
                        </div>
                        </div>
                        </div>
                        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
                        </body>
                        </html>